{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Other supported backends: tensorflow.compat.v1, tensorflow, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import deepxde.deepxde as dde\n",
    "import deepxde.deepxde.backend as bkd\n",
    "from datasets import makeTesting\n",
    "from datasets import parallel_solver, diffusion_reaction_solver\n",
    "from utils.func import dirichlet, periodic\n",
    "from utils.PDETriple import PDETripleCartesianProd\n",
    "from utils.test_model import normONet\n",
    "\n",
    "date = time.strftime(\"%Y%m%d-%H-%M-%S\", time.localtime())\n",
    "dde.config.set_random_seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_training_vx = 300\n",
    "ls = 0.05\n",
    "if False:\n",
    "    makeTesting_dr(length_scale = ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde(x, y, aux):\n",
    "    D = 0.01\n",
    "    k = 0.01\n",
    "    dy_t = dde.grad.jacobian(y, x[1], j=1)\n",
    "    dy_xx = dde.grad.hessian(y, x[1], j=0)\n",
    "    out = dy_t - D * dy_xx + k * y**2 - aux\n",
    "    return out\n",
    "\n",
    "class boundary():\n",
    "    def __init__(self, loss_coeff = 1, value = 0):\n",
    "        self.loss_coeff = loss_coeff\n",
    "        self.value = value\n",
    "    \n",
    "    def __call__(self, targets, outputs):\n",
    "        return self.loss_coeff * (outputs - self.value).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 101) (10201, 2) (20, 10201)\n",
      "(100, 101) (10201, 2) (100, 10201)\n"
     ]
    }
   ],
   "source": [
    "space = dde.data.GRF(1.0, length_scale = ls, N= 1000, interp=\"cubic\")\n",
    "\n",
    "geom = dde.geometry.Interval(0, 1)\n",
    "timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "vxs = space.eval_batch(space.random(20), np.linspace(0, 1, 101)[:, None])\n",
    "uxts = parallel_solver(diffusion_reaction_solver, vxs, num_workers = 0)\n",
    "grid = uxts[0][0].reshape(101 * 101, -1)\n",
    "uxts = np.asarray([u for grid, u in uxts]).reshape(-1, 101 * 101)\n",
    "\n",
    "\n",
    "train_vxs = vxs\n",
    "train_grid = grid\n",
    "train_uxts = uxts\n",
    "print(train_vxs.shape, train_grid.shape, train_uxts.shape)\n",
    "\n",
    "test_data = np.load(f\"datasets/DF_100_{ls:.2f}_101_101.npz\")\n",
    "test_vxs = test_data[\"vxs\"]\n",
    "test_grid = test_data[\"xt\"].reshape(-1, 2)\n",
    "test_uxts = test_data[\"uxts\"].reshape(-1, 101 * 101)\n",
    "del test_data\n",
    "print(test_vxs.shape, test_grid.shape, test_uxts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101,) (202,)\n"
     ]
    }
   ],
   "source": [
    "init_indices = (grid[:, 1] == 0).nonzero()[0]\n",
    "bound_indices = np.logical_or(grid[:, 0] == 0, grid[:, 0] == 1).nonzero()[0]\n",
    "boundary_losses = []\n",
    "boundary_losses.append((init_indices, boundary()))\n",
    "boundary_losses.append((bound_indices, boundary()))\n",
    "print(init_indices.shape, bound_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normONet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[39m=\u001b[39m PDETripleCartesianProd(X_train\u001b[39m=\u001b[39m(train_vxs, train_grid), y_train\u001b[39m=\u001b[39mtrain_uxts, X_test\u001b[39m=\u001b[39m(test_vxs, test_grid), y_test\u001b[39m=\u001b[39mtest_uxts, boundary \u001b[39m=\u001b[39m [])\n\u001b[1;32m      3\u001b[0m \u001b[39m# Net\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m net \u001b[39m=\u001b[39m normONet()\n\u001b[1;32m      6\u001b[0m \u001b[39m# net.apply_feature_transform(periodic)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m net\u001b[39m.\u001b[39mapply_output_transform(dirichlet)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normONet' is not defined"
     ]
    }
   ],
   "source": [
    "data = PDETripleCartesianProd(X_train=(train_vxs, train_grid), y_train=train_uxts, X_test=(test_vxs, test_grid), y_test=test_uxts, boundary = [])\n",
    "\n",
    "# Net\n",
    "net = normONet()\n",
    "\n",
    "# net.apply_feature_transform(periodic)\n",
    "net.apply_output_transform(dirichlet)\n",
    "\n",
    "model = dde.Model(data, net)\n",
    "model.compile(\"adam\", lr=1E-3, loss= [\"mse\"], metrics = [\"mean l2 relative error\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losshistory, train_state = model.train(iterations=20000, batch_size = 2)\n",
    "dde.utils.plot_loss_history(losshistory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losshistory.to_pandas().to_csv(f\"results/loss_history_{date}_ct2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "while len(train_vxs) < total_training_vx:\n",
    "    # generate some vxs to test\n",
    "    pde_data = dde.data.TimePDE(geomtime, pde, [], num_domain = 20000)\n",
    "    eval_pts = np.linspace(0, 1, 101)[:, None] # generate 1000 random vxs\n",
    "    geom = dde.geometry.Interval(0, 1)\n",
    "    timedomain = dde.geometry.TimeDomain(0, 1)\n",
    "    geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
    "    func_space = dde.data.GRF(1.0, length_scale = ls, N= 1000, interp=\"linear\")\n",
    "    testing_new_data = dde.data.PDEOperatorCartesianProd(pde_data, func_space, eval_pts, 20, [0])\n",
    "    # testing_model = dde.Model(testing_new_data, net)\n",
    "    a, _, c = testing_new_data.train_next_batch()\n",
    "    \n",
    "    uxts = parallel_solver(diffusion_reaction_solver, a[0], num_workers = 0)\n",
    "    uxts = np.asarray([u for grid, u in uxts]).reshape(-1, 101 * 101)\n",
    "\n",
    "    # then add the new data to the training set, and train the model\n",
    "    train_vxs = np.concatenate([train_vxs, a[0]], axis = 0)\n",
    "    train_uxts = np.concatenate([train_uxts, uxts], axis = 0)\n",
    "    \n",
    "    print(len(train_vxs))\n",
    "    data = PDETripleCartesianProd(X_train=(train_vxs, train_grid), y_train=train_uxts, X_test=(test_vxs, test_grid), y_test=test_uxts, boundary = [])\n",
    "    \n",
    "    model = dde.Model(data, net)\n",
    "    batchsize = len(train_vxs) // 5 if len(train_vxs) != total_training_vx else total_training_vx\n",
    "    iterations = 20000 if len(train_vxs) != total_training_vx else 50000\n",
    "    model.compile(\"adam\", \n",
    "                  lr=1e-3, \n",
    "                  metrics = [\"mean l2 relative error\"], \n",
    "                  decay = (\"inverse time\", 5000, 0.4))\n",
    "    losshistory, train_state = model.train(iterations=iterations, batch_size = batchsize)\n",
    "    pd_frame = losshistory.to_pandas()\n",
    "    pd_frame = pd.concat([pd.read_csv(f\"results/loss_history_{date}_ct2.csv\"), pd_frame], axis = 0, ignore_index=True)\n",
    "    pd_frame.to_csv(f\"results/loss_history_{date}_ct2.csv\", index=False)\n",
    "    dde.utils.plot_loss_history(losshistory)\n",
    "\n",
    "torch.save(model.state_dict(), f\"results/model_{date}_ct2.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
